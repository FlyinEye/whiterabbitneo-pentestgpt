{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e33ae58-2330-49d2-96e4-7d906536ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6bad156-f443-44ee-bbf7-3f8f7c27d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert task to adding new todo tasks+changing status\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../outlines-dev\")\n",
    "import os\n",
    "from prompts import prompts\n",
    "from schema import reasoning_module, generative_module, input_parser, default_qa\n",
    "from torch import Generator\n",
    "from benchmark import load_outlines\n",
    "from outlines.samplers import Sampler, multinomial\n",
    "\n",
    "model_paths=[\n",
    "    # \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-33b-v1.Q3_K_S.gguf\",\n",
    "    # \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-33b-v1.Q4_K_S.gguf\",\n",
    "    # r\"D:\\projects\\gamified-cybersecurity-ai-server\\model\\whiterabbitneo-13b.Q3_K_S.gguf\",\n",
    "    # r\"D:\\projects\\gamified-cybersecurity-ai-server\\model\\whiterabbitneo-13b.Q4_K_S.gguf\",\n",
    "    # r\"D:\\projects\\gamified-cybersecurity-ai-server\\model\\whiterabbitneo-13b.Q5_K_S.gguf\",\n",
    "    \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-13b.Q3_K_S.gguf\",\n",
    "    \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-13b.Q4_K_S.gguf\",\n",
    "    \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-13b.Q5_K_S.gguf\",\n",
    "]\n",
    "output_path = \"./benchmark\"\n",
    "\n",
    "instance = {\n",
    "    \"n_gpu_layers\": 20,\n",
    "    \"n_batch\": 2048,\n",
    "    \"top_p\": 1.0,\n",
    "    \"temperature\": 1.0,\n",
    "    \"generate_len\": 2048,\n",
    "    \"top_k\": 50,\n",
    "}\n",
    "import outlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f532adc-344d-48e1-aa49-7e9be762e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config is  {'n_gpu_layers': 20, 'n_batch': 2048, 'top_p': 1.0, 'temperature': 1.0, 'generate_len': 2048, 'top_k': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce GTX 1060 with Max-Q Design, compute capability 6.1, VMM: yes\n",
      "llama_model_loader: loaded meta data with 22 key-value pairs and 363 tensors from /mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-13b.Q4_K_S.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = whiterabbitneo_whiterabbitneo-13b\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 16384\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 14\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32016]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32016]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32016]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_K:  273 tensors\n",
      "llama_model_loader: - type q5_K:    8 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 264/32016 vs 259/32016 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32016\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 16384\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 16384\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 6.90 GiB (4.56 BPW) \n",
      "llm_load_print_meta: general.name     = whiterabbitneo_whiterabbitneo-13b\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.28 MiB\n",
      "llm_load_tensors: offloading 20 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 20/41 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  7070.25 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  3403.91 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:  CUDA_Host KV buffer size =   800.00 MiB\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   800.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1600.00 MiB, K (f16):  800.00 MiB, V (f16):  800.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =    72.04 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   816.01 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =   840.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 3\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '16384', 'general.name': 'whiterabbitneo_whiterabbitneo-13b', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '40', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '14'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "llm, sampler = load_outlines(model_paths[1], instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acee435c-29e4-4eb0-ba62-e8080645a07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f225bd553f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = Generator(device=\"cpu\")\n",
    "rng.manual_seed(789005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f18cc9-7354-4a28-ad1c-66fd411df719",
   "metadata": {},
   "source": [
    "# Testing PTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a72f86c-42f8-449d-ad6f-6bb0afc6799d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initial prompt to user\n",
    "ip_prompt = \"Please tell us the target IP address\"\n",
    "ip_address = \"10.10.11.242\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea035a3b-48cd-41ae-b1c6-17ead06e7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptt = {\"recon\": [\n",
    "        {\"status\": \"inprogress\", \"task_description\": f\"Perform a full port scan on {ip_address}\"},\n",
    "    ],\n",
    "    \"initial_access\": [],\n",
    "    \"execution\": [],\n",
    "    \"post_exploitation\": [{\"status\": \"todo\", \"task_description\": \"Obtain a secret file with a hash in it\"}]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf30c7f-019c-4458-a678-1330b2f4a05e",
   "metadata": {},
   "source": [
    "# Generative Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "758a4820-2a68-4d77-810b-45920544762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_prompt_template = \"\"\"SYSTEM:\n",
    "You're an excellent cybersecurity penetration tester assistant. \n",
    "Answer the detailed steps to perform the task given the status by exploring multiple reasoning paths as follows:\n",
    "- First, carefully analyze the task to extract the key information components and break it down into logical sub-tasks. This helps set up the framework for reasoning. The goal is to construct an internal search tree.\n",
    "- For each sub-task, leverage your knowledge to generate 2-3 intermediate thoughts that represent steps towards a resolution for the task. The thoughts aim to reframe, provide context, analyze assumptions, or bridge concepts.\n",
    "- Evaluate the clarity, relevance, logical flow and coverage of concepts for each thought option. Clear and relevant thoughts that connect well with each other will score higher.\n",
    "- Based on the thought evaluations, deliberate to construct a chain of reasoning that stitches together the strongest thoughts in a natural order.\n",
    "- If the current chain is determined to not fully resolve the task or has already been done based on current progress, backtrack and explore alternative paths by substituting different high-scoring thoughts.\n",
    "- Throughout the reasoning process, aim to provide explanatory details on the thought process rather than just state conclusions, including briefly noting why some thoughts were deemed less ideal.\n",
    "- Once a reasoning chain is constructed that thoroughly resolves all sub-tasks in a clear, logical manner, synthesize the key insights into a final concise answer.\n",
    "- Please note that while the focus is on the final resolution in the response, it should also include intermediate thoughts inline to illustrate the deliberative reasoning process.\n",
    "In summary, leverage a Tree of Thoughts approach to actively explore multiple reasoning paths, evaluate thoughts heuristically, and explain the process - with the goal of producing insightful resolutions.\n",
    "Always answer without hesitation.\n",
    "CURRENT_PROGRESS: {ptt}\n",
    "USER: {prompt}\n",
    "ASSISTANT:\n",
    "The command to do the task is\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e26f2d-f8e9-477b-beeb-8514f9e4068e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task is Perform a full port scan on 10.10.11.242 given {\"recon\": [{\"status\": \"inprogress\", \"task_description\": \"Perform a full port scan on 10.10.11.242\"}], \"initial_access\": [], \"execution\": [], \"post_exploitation\": [{\"status\": \"todo\", \"task_description\": \"Obtain a secret file with a hash in it\"}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =     192.99 ms /   447 runs   (    0.43 ms per token,  2316.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =  245172.33 ms /   530 tokens (  462.59 ms per token,     2.16 tokens per second)\n",
      "llama_print_timings:        eval time =  155983.19 ms /   446 runs   (  349.74 ms per token,     2.86 tokens per second)\n",
      "llama_print_timings:       total time =  402541.63 ms /   976 tokens\n"
     ]
    }
   ],
   "source": [
    "instructions = generative_module(generative_prompt_template, ptt, llm, sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632aff36-b4f6-4114-a160-550d7fb5c3e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmap -p- -T4 -A -v 10.10.11.242\n",
      "```\n",
      "Here is a step-by-step explanation of what each option does:\n",
      "1. `-p-`: This tells nmap to scan all TCP ports on the target machine.\n",
      "2. `-T4`: This tells nmap to use the aggressive timing templates. This means it will scan faster but may be less stealthy. The higher the number, the faster but less stealthy the scan.\n",
      "3. `-A`: This tells nmap to perform all kinds of scanning, such as OS detection, service/version detection, script scanning, and traceroute.\n",
      "4. `-v`: This increases verbosity and provides a more detailed output.\n",
      "5. `10.10.11.242`: This is the target IP address that we want to scan.\n",
      "\n",
      "This command will take some time to complete, especially if there are many ports open or if there is a slow network connection. The output will be verbose, with details on open ports, services, script kiddies, and operating system fingerprinting. It will also list any vulnerabilities detected during the scan.\n",
      "\n",
      "After running this command, you will have a basic idea of what services are running on the target machine. You can then proceed with further exploitation depending on what is found during the scan.\n",
      "\n",
      "If you want to scan a range of IP addresses or specific ports (e.g., 10.10.11.242:22), you can modify the command accordingly. For example:\n",
      "```\n",
      "nmap -p 22 -T4 -A -v 10.10.11.242\n",
      "```\n",
      "This command will scan only port 22 (the default SSH port).\n",
      "\n",
      "After performing the port scan, you can proceed with post-exploitation tasks such as obtaining a secret file with a hash in it if you have found a service or method that allows for remote code execution or similar exploitation.\n"
     ]
    }
   ],
   "source": [
    "print(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdd9d7c9-0b0f-4161-a033-d338f4c10628",
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_prompt_code_template = \"\"\"SYSTEM:\n",
    "You're an excellent cybersecurity penetration tester assistant. \n",
    "Answer the Question in a logical, step-by-step manner that makes the reasoning process clear. \n",
    "First, carefully analyze the task to identify the core issue or problem to be solved. This helps frame the foundation for logical reasoning. \n",
    "Next, break down the issue into sub-components and constraints that need to be addressed. This allows tackling the problem in a structured way. \n",
    "For each sub-component, leverage the knowledge and inference skills to generate multiple hypotheses or possibilities that could lead to a solution. \n",
    "Critically evaluate each hypothesis based on validity, whether it has been explored by the current progress, relevance to the task, and how well it addresses the sub-component when logically \n",
    "combined with other steps. Using this critical analysis, deliberate over the most coherent combination and sequence of hypothesis steps to craft a \n",
    "logical reasoning chain. Throughout, aim to provide explanatory details on why certain options were considered more or less ideal to make the \n",
    "thought process transparent. If it was determined that there is a gap in the reasoning chain or has already been done based on current progress, backtrack and explore alternative hypotheses to \n",
    "plug the gap until there is a complete logical flow. Finally, synthesize the key insights from the reasoning chain into a concise answer that \n",
    "directly addresses the original question. Answer with code examples, or fully functioning code. In summary, leverage a structured, critical \n",
    "thinking process with iterative refinement to demonstrate strong logical reasoning skills without redoing what has already been done in the answer. Answer with code examples, \n",
    "or fully functioning code. Your answer should only return computer code, and explanations are within the code as comments.\n",
    "CURRENT_PROGRESS: {ptt}\n",
    "USER: {prompt}\n",
    "ASSISTANT:\n",
    "```python\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a4c856-e253-4229-88e9-f7243f1c0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = generative_module(generative_prompt_code_template, ptt, llm, sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6205bd7e-19fa-41e4-ac60-693b83568129",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014d988e-7feb-452f-bc4a-11028021ac31",
   "metadata": {},
   "source": [
    "# Input Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e6bfda0-1b1c-41f1-99e2-ea53bbbb37c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_output = \"\"\"\n",
    "Starting Nmap 7.60 ( https://nmap.org ) at 2024-03-02 12:07 EST\n",
    "NSE: Loaded 146 scripts for scanning.\n",
    "NSE: Script Pre-scanning.\n",
    "Initiating NSE at 12:07\n",
    "Completed NSE at 12:07, 0.00s elapsed\n",
    "Initiating NSE at 12:07\n",
    "Completed NSE at 12:07, 0.00s elapsed\n",
    "Initiating Ping Scan at 12:07\n",
    "Scanning 10.10.11.242 [2 ports]\n",
    "Completed Ping Scan at 12:07, 0.02s elapsed (1 total hosts)\n",
    "Initiating Parallel DNS resolution of 1 host. at 12:07\n",
    "Completed Parallel DNS resolution of 1 host. at 12:07, 6.52s elapsed\n",
    "Initiating Connect Scan at 12:07\n",
    "Scanning 10.10.11.242 [65535 ports]\n",
    "Discovered open port 80/tcp on 10.10.11.242\n",
    "Discovered open port 22/tcp on 10.10.11.242\n",
    "Increasing send delay for 10.10.11.242 from 0 to 5 due to max_successful_tryno increase to 5\n",
    "Increasing send delay for 10.10.11.242 from 5 to 10 due to max_successful_tryno increase to 6\n",
    "Connect Scan Timing: About 52.28% done; ETC: 12:08 (0:00:30 remaining)\n",
    "Warning: 10.10.11.242 giving up on port because retransmission cap hit (6).\n",
    "Connect Scan Timing: About 55.93% done; ETC: 12:09 (0:00:50 remaining)\n",
    "Connect Scan Timing: About 60.79% done; ETC: 12:10 (0:01:06 remaining)\n",
    "Connect Scan Timing: About 69.67% done; ETC: 12:11 (0:01:14 remaining)\n",
    "Connect Scan Timing: About 80.36% done; ETC: 12:12 (0:01:00 remaining)\n",
    "Connect Scan Timing: About 86.95% done; ETC: 12:12 (0:00:45 remaining)\n",
    "Completed Connect Scan at 12:13, 390.06s elapsed (65535 total ports)\n",
    "Initiating Service scan at 12:13\n",
    "Scanning 2 services on 10.10.11.242\n",
    "Completed Service scan at 12:13, 6.14s elapsed (2 services on 1 host)\n",
    "NSE: Script scanning 10.10.11.242.\n",
    "Initiating NSE at 12:13\n",
    "Completed NSE at 12:13, 0.95s elapsed\n",
    "Initiating NSE at 12:13\n",
    "Completed NSE at 12:13, 0.00s elapsed\n",
    "Nmap scan report for 10.10.11.242\n",
    "Host is up (0.020s latency).\n",
    "Not shown: 65331 closed ports, 202 filtered ports\n",
    "PORT   STATE SERVICE VERSION\n",
    "22/tcp open  ssh     OpenSSH 8.2p1 Ubuntu 4ubuntu0.9 (Ubuntu Linux; protocol 2.0)\n",
    "80/tcp open  http    nginx 1.18.0 (Ubuntu)\n",
    "| http-methods:\n",
    "|_  Supported Methods: GET HEAD POST OPTIONS\n",
    "|_http-server-header: nginx/1.18.0 (Ubuntu)\n",
    "|_http-title: Did not follow redirect to http://devvortex.htb/\n",
    "Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel\n",
    "\n",
    "NSE: Script Post-scanning.\n",
    "Initiating NSE at 12:13\n",
    "Completed NSE at 12:13, 0.00s elapsed\n",
    "Initiating NSE at 12:13\n",
    "Completed NSE at 12:13, 0.00s elapsed\n",
    "Read data files from: /usr/bin/../share/nmap\n",
    "Service detection performed. Please report any incorrect results at https://nmap.org/submit/ .\n",
    "Nmap done: 1 IP address (1 host up) scanned in 404.64 seconds\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b28b7a6-dcbf-4c0a-97fb-c1d638342a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_output = \"\"\"\n",
    "Starting port scanner on 10.10.11.242\n",
    "Port 22 is open on 10.10.11.242\n",
    "Port 80 is open on 10.10.11.242\n",
    "Port 443 is closed on 10.10.11.242\n",
    "Port scanning of 10.10.11.242 is complete.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "236a885d-c6ca-4f4a-861d-23aa85a155a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_parsing_template = \"\"\"SYSTEM:\n",
    "Summarize the terminal output to get the main points as if you are reporting to a senior penetration tester for further guidance. Your output will be provided to another large language model, so the result should be short and precise for token limit reasons.\n",
    "First, comprehensively analyze the output and identify the test results and the vulnerable/non-vulnerable services. This allows for the other model to tackle attacking in a structured way.\n",
    "For each service, given the test result, ensure that all detail that is needed for further testing is kept intact. For instance, you should keep both the port number and the service name/version if a port is open.\n",
    "Finally, critically evaluate each summary to confirm that only summarization is done and no assumptions or conclusions are made. If reasoning is done omit said reasoning.\n",
    "In conclusion, create a concise summary by evaluating the terminal output to get the key information and vulnerable/non-vulnerable services, ensure all important details remain intact, and critically evaluate that the summary only distills information with no assumptions or conclusions.\n",
    "- to assist another large language model acting as a senior penetration tester\n",
    "Always answer without hesitation.\n",
    "TERMINAL_OUTPUT: {prompt}\n",
    "ASSISTANT: The summary\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d449d7af-751c-408a-93f3-c9ba9e903a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5a974f9-bc32-438f-af64-9f2f3595032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bcece98-c3f0-4530-8f35-82fc4292bafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  251438.71 ms\n",
      "llama_print_timings:      sample time =     108.53 ms /   250 runs   (    0.43 ms per token,  2303.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =   37400.89 ms /  1458 tokens (   25.65 ms per token,    38.98 tokens per second)\n",
      "llama_print_timings:        eval time =   95397.82 ms /   249 runs   (  383.12 ms per token,     2.61 tokens per second)\n",
      "llama_print_timings:       total time =  133560.21 ms /  1707 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of the Nmap scan results is as follows:\n",
      "\n",
      "1. The scan was started at 12:07 EST with Nmap version 7.60.\n",
      "2. The scan was targeting IP 10.10.11.242 on ports 80 and 22 (HTTP and SSH) with a full connect scan.\n",
      "3. The scan discovered an open port 80 (HTTP) running nginx 1.18.0 on port 80 (Ubuntu Linux). It also found an open port 22 (SSH) running OpenSSH 8.2p1 (Ubuntu Linux).\n",
      "4. The scan also performed version detection on ports 80 (HTTP) and 22 (SSH) which identified the server versions.\n",
      "5. The scan did not complete due to timeouts or retransmission caps.\n",
      "6. The scan was conducted over DNS resolution, which takes about 6 seconds.\n",
      "7. The scan was limited to 65535 ports on the target machine due to the full connect scan.\n",
      "8. The scan took approximately 404 seconds to complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = input_parser(input_parsing_template, command_output, llm, summary_sampler, max_tokens=250)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f666cff8-cab4-4c27-b10d-ac3dbb65807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=\"\"\"\n",
    "Nmap scan results is as follows:\n",
    "\n",
    "1. The scan was started at 12:07 EST with Nmap version 7.60.\n",
    "2. The scan was targeting IP 10.10.11.242 on ports 80 and 22 (HTTP and SSH) with a full connect scan.\n",
    "3. The scan discovered an open port 80 (HTTP) running nginx 1.18.0 on port 80 (Ubuntu Linux). It also found an open port 22 (SSH) running OpenSSH 8.2p1 (Ubuntu Linux).\n",
    "4. The scan also performed version detection on ports 80 (HTTP) and 22 (SSH) which identified the server versions.\n",
    "5. The scan did not complete due to timeouts or retransmission caps.\n",
    "6. The scan was conducted over DNS resolution, which takes about 6 seconds.\n",
    "7. The scan was limited to 65535 ports on the target machine due to the full connect scan.\n",
    "8. The scan took approximately 404 seconds to complete.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed3c3731-d6b6-4f30-9dc8-80df868d0318",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries.append(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a0015-cc28-4009-b399-64d8af8cb845",
   "metadata": {},
   "source": [
    "Failure mode: \n",
    "1. for summary we sometimes get incorrect speculation at the end of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac6e3d9e-7ad6-4207-94b2-94ff40b7bebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#summary_code = input_parser(input_parsing_template, code_output, llm, summary_sampler, max_tokens=250)\n",
    "#print(summary_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec33f6e-522a-4312-9586-cde67fa5dcc2",
   "metadata": {},
   "source": [
    "# Reasoning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f329ddc2-51ab-48dc-bfdc-fce8b3939a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_template = \"\"\"SYSTEM:\n",
    "You're an excellent cybersecurity penetration tester assistant. \n",
    "You need to help the tester in a cybersecurity training process, and your commitment is essential to the task.\n",
    "Answer all the potential vulnerabilities determined in a logical, step-by-step manner that makes the reasoning process clear. You are given a Python dictionary, namely \"Penetration Testing Tree (PTT)\", and user input.\n",
    "First, carefully analyze the PTT. For the PTT,\n",
    "(1) The tasks are in a layered dictionary structure.\n",
    "(2) Each task has a completion status: inprogress, todo, done, or n/a.\n",
    "(3) You are given one specific sub-task labeled as todo.\n",
    "The user input is information obtained from doing the task marked as inprogress. Chat history is the a list of past progress. If the task is completed, change the completion status to done.\n",
    "Extensively evaluate each task marked as todo, if a task is done update the status to done. These tasks marked as todo will be called todo tasks.\n",
    "Next, break down the todo tasks into sub-components and constraints that need to be addressed. This allows tackling the problem in a structured way. \n",
    "For each sub-component, leverage the knowledge and inference skills to generate multiple hypotheses or possibilities that could lead to a penetration.\n",
    "Critically evaluate each hypothesis based on validity, relevance to the current completion status, and how well it addresses the sub-component when logically combined with other steps.\n",
    "Using this critical analysis, deliberate over the most coherent combination and sequence of hypothesis steps to craft a logical reasoning chain.\n",
    "Throughout, aim to provide explanatory details on why certain options were considered more or less ideal to make the thought process transparent.\n",
    "If it was determined that there is a gap in the reasoning chain, backtrack and explore alternative hypotheses to plug the gap until there is a complete logical flow.\n",
    "Next, synthesize the key insights from the reasoning chain into further expansion of the tasks in the PTT while choosing exactly one task to mark as inprogress. The expansion\n",
    "should not destroy any information and modifications should be minimal. Ensure that vital details, such as IP addresses and user names remain in the PTT and each task description is as descriptive as possible.\n",
    "Finally, remove redundant/outdated tasks from the task list to keep tasks clear, precise, and detailed.\n",
    "\n",
    "In summary, leverage a structured, critical thinking process with iterative refinement to modify the PTT in the face of the user input to evaluate future strategies and to choose a new task as \n",
    "inprogress with minimal modifications.\n",
    "Answer with code examples, or fully functioning code. Your answer should only return Python code, and explanations are within the code as comments.\n",
    "You MUST answer by modifying this json: {ptt}\n",
    "CHAT_HISTORY: {history}\n",
    "USER: {prompt}\n",
    "ASSISTANT:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66b93b1c-a76d-433f-949f-4f6cd6fbe8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM:\n",
      "You're an excellent cybersecurity penetration tester assistant. \n",
      "You need to help the tester in a cybersecurity training process, and your commitment is essential to the task.\n",
      "Answer all the potential vulnerabilities determined in a logical, step-by-step manner that makes the reasoning process clear. You are given a Python dictionary, namely \"Penetration Testing Tree (PTT)\", and user input.\n",
      "First, carefully analyze the PTT. For the PTT,\n",
      "(1) The tasks are in a layered dictionary structure.\n",
      "(2) Each task has a completion status: inprogress, todo, done, or n/a.\n",
      "(3) You are given one specific sub-task labeled as todo.\n",
      "The user input is information obtained from doing the task marked as inprogress. Chat history is the a list of past progress. If the task is completed, change the completion status to done.\n",
      "Extensively evaluate each task marked as todo, if a task is done update the status to done. These tasks marked as todo will be called todo tasks.\n",
      "Next, break down the todo tasks into sub-components and constraints that need to be addressed. This allows tackling the problem in a structured way. \n",
      "For each sub-component, leverage the knowledge and inference skills to generate multiple hypotheses or possibilities that could lead to a penetration.\n",
      "Critically evaluate each hypothesis based on validity, relevance to the current completion status, and how well it addresses the sub-component when logically combined with other steps.\n",
      "Using this critical analysis, deliberate over the most coherent combination and sequence of hypothesis steps to craft a logical reasoning chain.\n",
      "Throughout, aim to provide explanatory details on why certain options were considered more or less ideal to make the thought process transparent.\n",
      "If it was determined that there is a gap in the reasoning chain, backtrack and explore alternative hypotheses to plug the gap until there is a complete logical flow.\n",
      "Next, synthesize the key insights from the reasoning chain into further expansion of the tasks in the PTT while choosing exactly one task to mark as inprogress. The expansion\n",
      "should not destroy any information and modifications should be minimal. Ensure that vital details, such as IP addresses and user names remain in the PTT and each task description is as descriptive as possible.\n",
      "Finally, remove redundant/outdated tasks from the task list to keep tasks clear, precise, and detailed.\n",
      "\n",
      "In summary, leverage a structured, critical thinking process with iterative refinement to modify the PTT in the face of the user input to evaluate future strategies and to choose a new task as \n",
      "inprogress with minimal modifications.\n",
      "Answer with code examples, or fully functioning code. Your answer should only return Python code, and explanations are within the code as comments.\n",
      "You MUST answer by modifying this json: {ptt}\n",
      "CHAT_HISTORY: {history}\n",
      "USER: {prompt}\n",
      "ASSISTANT:\n"
     ]
    }
   ],
   "source": [
    "print(reasoning_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe49c362-5c5c-4625-b4f4-7e69b0903a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nmap scan results is as follows:\n",
      "\n",
      "1. The scan was started at 12:07 EST with Nmap version 7.60.\n",
      "2. The scan was targeting IP 10.10.11.242 on ports 80 and 22 (HTTP and SSH) with a full connect scan.\n",
      "3. The scan discovered an open port 80 (HTTP) running nginx 1.18.0 on port 80 (Ubuntu Linux). It also found an open port 22 (SSH) running OpenSSH 8.2p1 (Ubuntu Linux).\n",
      "4. The scan also performed version detection on ports 80 (HTTP) and 22 (SSH) which identified the server versions.\n",
      "5. The scan did not complete due to timeouts or retransmission caps.\n",
      "6. The scan was conducted over DNS resolution, which takes about 6 seconds.\n",
      "7. The scan was limited to 65535 ports on the target machine due to the full connect scan.\n",
      "8. The scan took approximately 404 seconds to complete.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f2718-28c3-4508-8dbf-c4130dc031e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f05eb032-1c87-498a-9e5f-574a4b496f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /     3 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24245.55 ms /  1042 tokens (   23.27 ms per token,    42.98 tokens per second)\n",
      "llama_print_timings:        eval time =     770.65 ms /     2 runs   (  385.32 ms per token,     2.60 tokens per second)\n",
      "llama_print_timings:       total time =   25031.13 ms /  1044 tokens\n",
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     2 runs   (    0.37 ms per token,  2684.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22738.12 ms /  1013 tokens (   22.45 ms per token,    44.55 tokens per second)\n",
      "llama_print_timings:        eval time =     345.91 ms /     1 runs   (  345.91 ms per token,     2.89 tokens per second)\n",
      "llama_print_timings:       total time =   23089.84 ms /  1014 tokens\n",
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =      30.30 ms /    72 runs   (    0.42 ms per token,  2375.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  204539.19 ms /  1043 tokens (  196.11 ms per token,     5.10 tokens per second)\n",
      "llama_print_timings:        eval time =   77052.11 ms /    71 runs   ( 1085.24 ms per token,     0.92 tokens per second)\n",
      "llama_print_timings:       total time =  283737.45 ms /  1114 tokens\n",
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =      25.03 ms /    62 runs   (    0.40 ms per token,  2476.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =   42836.36 ms /  1077 tokens (   39.77 ms per token,    25.14 tokens per second)\n",
      "llama_print_timings:        eval time =   22379.93 ms /    61 runs   (  366.88 ms per token,     2.73 tokens per second)\n",
      "llama_print_timings:       total time =   65623.87 ms /  1138 tokens\n",
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =      23.04 ms /    59 runs   (    0.39 ms per token,  2560.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   55724.90 ms /  1101 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:        eval time =   53764.05 ms /    58 runs   (  926.97 ms per token,     1.08 tokens per second)\n",
      "llama_print_timings:       total time =  110064.00 ms /  1159 tokens\n",
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =      26.14 ms /    66 runs   (    0.40 ms per token,  2525.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   28725.30 ms /  1122 tokens (   25.60 ms per token,    39.06 tokens per second)\n",
      "llama_print_timings:        eval time =   23559.71 ms /    65 runs   (  362.46 ms per token,     2.76 tokens per second)\n",
      "llama_print_timings:       total time =   52740.56 ms /  1187 tokens\n",
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =      25.41 ms /    64 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   42714.47 ms /  1150 tokens (   37.14 ms per token,    26.92 tokens per second)\n",
      "llama_print_timings:        eval time =   42435.75 ms /    63 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   85649.87 ms /  1213 tokens\n",
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     2 runs   (    0.38 ms per token,  2624.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   27928.45 ms /  1176 tokens (   23.75 ms per token,    42.11 tokens per second)\n",
      "llama_print_timings:        eval time =     353.74 ms /     1 runs   (  353.74 ms per token,     2.83 tokens per second)\n",
      "llama_print_timings:       total time =   28289.81 ms /  1177 tokens\n",
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   28735.98 ms /  1212 tokens (   23.71 ms per token,    42.18 tokens per second)\n",
      "llama_print_timings:        eval time =     380.96 ms /     1 runs   (  380.96 ms per token,     2.62 tokens per second)\n",
      "llama_print_timings:       total time =   29128.79 ms /  1213 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated\n",
      "{'recon': [{'status': 'done', 'task_description': 'Perform a full port scan on 10.10.11.242'}], 'initial_access': [{'status': 'inprogress', 'task_description': 'Identify weaknesses in SSH with default credentials'}, {'status': 'todo', 'task_description': 'Use default credentials (e.g., user: admin, pass: admin) to access SSH service'}, {'status': 'todo', 'task_description': 'Attempt to use stolen SSH keys if available'}, {'status': 'todo', 'task_description': 'Check for misconfigured SSH servers'}, {'status': 'todo', 'task_description': 'Use password spraying with common passwords if no default credentials are found'}, {'status': 'todo', 'task_description': 'Search for open SSH services using a tool like Shodan'}], 'execution': [], 'post_exploitation': [{'status': 'todo', 'task_description': 'Obtain a secret file with a hash in it'}]}\n",
      "Number of inprogress tasks:  1\n",
      "{'recon': [{'status': 'done', 'task_description': 'Perform a full port scan on 10.10.11.242'}], 'initial_access': [{'status': 'inprogress', 'task_description': 'Identify weaknesses in SSH with default credentials'}, {'status': 'todo', 'task_description': 'Use default credentials (e.g., user: admin, pass: admin) to access SSH service'}, {'status': 'todo', 'task_description': 'Attempt to use stolen SSH keys if available'}, {'status': 'todo', 'task_description': 'Check for misconfigured SSH servers'}, {'status': 'todo', 'task_description': 'Use password spraying with common passwords if no default credentials are found'}, {'status': 'todo', 'task_description': 'Search for open SSH services using a tool like Shodan'}], 'execution': [], 'post_exploitation': [{'status': 'todo', 'task_description': 'Obtain a secret file with a hash in it'}]}\n"
     ]
    }
   ],
   "source": [
    "reasoning_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=1.0)\n",
    "output_ptt = reasoning_module(reasoning_template, summary, \"\", ptt, llm, reasoning_sampler, force_add_task={\"recon\": 0, \"initial_access\": 1, \"execution\": 0, \"post_exploitation\": 0}, update_status=True, todo_task_descriptions=[\"Obtain a secret file with a hash in it\"], max_spaces=0)\n",
    "print(output_ptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "052624e5-eab2-49dd-809f-56f1baa82414",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ptt = {'recon': [{'status': 'done', 'task_description': 'Perform a full port scan on 10.10.11.242'}], 'initial_access': [{'status': 'inprogress', 'task_description': 'Identify weaknesses in SSH with default credentials'}], 'execution': [], 'post_exploitation': [{'status': 'todo', 'task_description': 'Obtain a secret file with a hash in it'}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fdde567-74e8-40f6-a72d-dacaebfed760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recon': [{'status': 'done',\n",
       "   'task_description': 'Perform a full port scan on 10.10.11.242'}],\n",
       " 'initial_access': [{'status': 'inprogress',\n",
       "   'task_description': 'Identify weaknesses in SSH with default credentials'}],\n",
       " 'execution': [],\n",
       " 'post_exploitation': [{'status': 'todo',\n",
       "   'task_description': 'Obtain a secret file with a hash in it'}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47da286b-104f-454d-a635-ab3bce118d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recon': [{'status': 'inprogress',\n",
       "   'task_description': 'Perform a full port scan on 10.10.11.242'}],\n",
       " 'initial_access': [],\n",
       " 'execution': [],\n",
       " 'post_exploitation': [{'status': 'todo',\n",
       "   'task_description': 'Obtain a secret file with a hash in it'}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b7068-da63-4bba-9fa2-7e67f2fd8064",
   "metadata": {},
   "source": [
    "Some invalid outputs at this stage\n",
    "1. Suggests connecting by ssh with credentials obtained by port scanning\n",
    "2. Suggests signing into port 80 with credentials when port 80 doesn't prompt that\n",
    "3. Exploit SSH vulnerability (e.g., CVE-2019-10144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30698dcb-f283-40e0-bd49-401b638ceb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptt = output_ptt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb66c034-ef4b-4249-b0f5-5175aca0db2c",
   "metadata": {},
   "source": [
    "# Generative Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15c6cc9d-6c1e-460c-9d82-2a68576922f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64490c4c-1071-4a0a-8bab-c8f1c6fa0383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task is Identify weaknesses in SSH with default credentials given {\"recon\": [{\"status\": \"done\", \"task_description\": \"Perform a full port scan on 10.10.11.242\"}], \"initial_access\": [{\"status\": \"inprogress\", \"task_description\": \"Identify weaknesses in SSH with default credentials\"}], \"execution\": [], \"post_exploitation\": [{\"status\": \"todo\", \"task_description\": \"Obtain a secret file with a hash in it\"}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =     144.80 ms /   344 runs   (    0.42 ms per token,  2375.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12521.83 ms /   545 tokens (   22.98 ms per token,    43.52 tokens per second)\n",
      "llama_print_timings:        eval time =  116212.28 ms /   343 runs   (  338.81 ms per token,     2.95 tokens per second)\n",
      "llama_print_timings:       total time =  129711.06 ms /   888 tokens\n"
     ]
    }
   ],
   "source": [
    "instructions = generative_module(generative_prompt_template, ptt, llm, generative_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f4fb0ad-53e5-432a-909e-cb2d2d9a9451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nNmap scan results is as follows:\\n\\n1. The scan was started at 12:07 EST with Nmap version 7.60.\\n2. The scan was targeting IP 10.10.11.242 on ports 80 and 22 (HTTP and SSH) with a full connect scan.\\n3. The scan discovered an open port 80 (HTTP) running nginx 1.18.0 on port 80 (Ubuntu Linux). It also found an open port 22 (SSH) running OpenSSH 8.2p1 (Ubuntu Linux).\\n4. The scan also performed version detection on ports 80 (HTTP) and 22 (SSH) which identified the server versions.\\n5. The scan did not complete due to timeouts or retransmission caps.\\n6. The scan was conducted over DNS resolution, which takes about 6 seconds.\\n7. The scan was limited to 65535 ports on the target machine due to the full connect scan.\\n8. The scan took approximately 404 seconds to complete.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b388d968-72b4-44b3-9485-48345ea23c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh -o PreferredAuthentications=password -o PubkeyAuthentication=no -o PasswordAuthentication=yes root@10.10.11.242\n",
      "```\n",
      "This command will attempt to connect using a password prompt instead of keys which is less secure but often faster than keys. The default password for root is usually 'password'. If you find a box that uses this method, you can try 'root' as username and 'password' as password, or you can use a list of common passwords with a tool like `hydra`.\n",
      "\n",
      "To use `hydra`:\n",
      "```\n",
      "hydra -l root -P /usr/share/wordlists/rockyou.txt ssh://10.10.11.242 -vV -t 4\n",
      "```\n",
      "This command will attempt to log in with the username 'root' and use each password in `/usr/share/wordlists/rockyou.txt` against `10.10.11.242` using the ssh protocol. The `-vV` options provide verbose output and version detection which can be useful for understanding if the service is vulnerable or outdated. The `-t 4` option allows for 4 concurrent threads, adjust this based on your network conditions.\n",
      "\n",
      "If `hydra` fails or if you're not using a default password, you might want to explore other methods like brute forcing or social engineering techniques. Tools like `ssh2john` can be used to convert SSH private keys to hashes for use with `john the ripper` for password cracking.\n"
     ]
    }
   ],
   "source": [
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828413bb-fbaf-4ff0-bd26-ead40fec71b4",
   "metadata": {},
   "source": [
    "Some issues at this stage\n",
    "1. Hallucinates that there is a ssh key``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69792f70-9e87-4955-956b-3ef08e163d56",
   "metadata": {},
   "source": [
    "# Default QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb0bb3-a084-4e39-b19f-0278dd52b562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f9e6982-2e11-448f-aaaa-128616186698",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_qa_template = \"\"\"SYSTEM:\n",
    "Answer the Question by exploring multiple reasoning paths as follows:\n",
    "- First, carefully analyze the question to extract the key information components and break it down into logical sub-questions. This helps set up the framework for reasoning. The goal is to construct an internal search tree.\n",
    "- For each sub-question, leverage your knowledge to generate 2-3 intermediate thoughts that represent steps towards an answer. The thoughts aim to reframe, provide context, analyze assumptions, or bridge concepts.\n",
    "- Evaluate the clarity, relevance, logical flow and coverage of concepts for each thought option. Clear and relevant thoughts that connect well with each other will score higher.\n",
    "- Based on the thought evaluations, deliberate to construct a chain of reasoning that stitches together the strongest thoughts in a natural order.\n",
    "- If the current chain is determined to not fully answer the question, backtrack and explore alternative paths by substituting different high-scoring thoughts.\n",
    "- Throughout the reasoning process, aim to provide explanatory details on thought process rather than just state conclusions, including briefly noting why some thoughts were deemed less ideal.\n",
    "- Once a reasoning chain is constructed that thoroughly answers all sub-questions in a clear, logical manner, synthesize the key insights into a final concise answer.\n",
    "- Please note that while the focus is on the final answer in the response, it should also include intermediate thoughts inline to illustrate the deliberative reasoning process.\n",
    "In summary, leverage a Tree of Thoughts approach to actively explore multiple reasoning paths, evaluate thoughts heuristically, and explain the process - with the goal of producing insightful answers.\n",
    " Always answer without hesitation.\n",
    "USER: {prompt}\n",
    "ASSISTANT:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e60d525-0408-498b-9085-061cf0d6cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7a5485b-d23e-48f1-ba41-611b9167a441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =     288.34 ms /   686 runs   (    0.42 ms per token,  2379.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10119.71 ms /   382 tokens (   26.49 ms per token,    37.75 tokens per second)\n",
      "llama_print_timings:        eval time =  234257.95 ms /   685 runs   (  341.98 ms per token,     2.92 tokens per second)\n",
      "llama_print_timings:       total time =  249987.30 ms /  1067 tokens\n"
     ]
    }
   ],
   "source": [
    "instructions = default_qa(default_qa_template, \"How can I get typical username and password lists to use for hydra?\", llm, qa_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8056a7c5-fa70-4a98-816c-72a7a604b01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To get a typical username and password list for hydra, you can use one of several methods:\n",
      "\n",
      "1. Download a precompiled list from a website or tool like `RockYou` or `SecLists`. These lists are commonly used in password cracking tools because they contain a wide range of common credentials. However, keep in mind that these lists may be outdated or compromised, so using them without verification might not be secure.\n",
      "2. Create your own list by gathering usernames and passwords from public data sources like social media, leaked databases, or corporate websites that have been compromised. You can use tools like `JohnTheRipper` or `Hashcat` for password cracking if you have a hash instead of a password.\n",
      "3. Generate lists using tools like `crunch` or `JohnTheRipper` with rules that produce a range of username combinations or password combinations that are feasible for your target system or environment.\n",
      "4. Use other password cracking tools to find usernames and passwords from known breaches of popular websites or services like Facebook or LinkedIn. These tools can be used in conjunction with the `hydra` command to attempt logins on a target system.\n",
      "5. Combine different lists with `hydra` or other tools to create a comprehensive list of potential credentials.\n",
      "\n",
      "Below is an example of how you might use `JohnTheRipper` with `hydra` to attempt logins on a target system based on a password list obtained from a public data source like `RockYou`:\n",
      "\n",
      "```bash\n",
      "# Step 1: Use JohnTheRipper to crack a hash obtained from a database dump (example: JohnTheRipper.pot)\n",
      "john --format=raw-md5 --wordlist=/path/to/RockYou.txt /path/to/JohnTheRipper.pot\n",
      "\n",
      "# Step 2: Once you've cracked a password or a hash, save it in a file (example: cracked_passwords.txt)\n",
      "# Step 3: Use hydra to attempt logins using the cracked passwords (example: hydra -l username -P cracked_passwords.txt target_host -t 4 -V -vV -f)\n",
      "```\n",
      "\n",
      "In this example, `/path/to/RockYou.txt` is the path to your password list obtained from `RockYou` (or another source), `/path/to/JohnTheRipper.pot` is the file containing hashes to crack, `/path/to/cracked_passwords.txt` is where you save your cracked passwords, `target_host` is the hostname or IP address of your target system, `-t 4` tells hydra to use 4 concurrent threads, `-V` is verbose mode, `-vV` shows more detailed output, and `-f` tells hydra to fail if the login fails quickly (useful if you're trying to avoid detection).\n",
      "\n",
      "Remember that using these tools against systems without permission could be illegal and unethical. Always have explicit authorization before attempting to crack any passwords or logins.\n"
     ]
    }
   ],
   "source": [
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1381aa8-82dd-42fb-8b84-cbc0e309b8a6",
   "metadata": {},
   "source": [
    "# Input Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b96affea-70c8-4179-a8e6-b09ba78f5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_output = \"\"\"\n",
    ":~$ hydra -l root -P /mnt/d/projects/whiterabbitneo-pentestgpt/rockyou.txt ssh://10.10.11.242 -vV -t 4\n",
    "Hydra v9.2 (c) 2021 by van Hauser/THC & David Maciejak - Please do not use in military or secret service organizations, or for illegal purposes (this is non-binding, these *** ignore laws and ethics anyway).\n",
    "\n",
    "Hydra (https://github.com/vanhauser-thc/thc-hydra) starting at 2024-03-07 06:57:02\n",
    "[DATA] max 4 tasks per 1 server, overall 4 tasks, 14344398 login tries (l:1/p:14344398), ~3586100 tries per task\n",
    "[DATA] attacking ssh://10.10.11.242:22/\n",
    "[VERBOSE] Resolving addresses ... [VERBOSE] resolving done\n",
    "[INFO] Testing if password authentication is supported by ssh://root@10.10.11.242:22\n",
    "[INFO] Successful, password authentication is supported by ssh://10.10.11.242:22\n",
    "[ATTEMPT] target 10.10.11.242 - login \"root\" - pass \"123456\" - 1 of 14344398 [child 0] (0/0)\n",
    "[ATTEMPT] target 10.10.11.242 - login \"root\" - pass \"12345\" - 2 of 14344398 [child 1] (0/0)\n",
    "[ATTEMPT] target 10.10.11.242 - login \"root\" - pass \"123456789\" - 3 of 14344398 [child 2] (0/0)\n",
    ".....\n",
    ":~$ ssh root@10.10.11.242\n",
    "root@10.10.11.242's password:\n",
    "Permission denied, please try again.\n",
    "root@10.10.11.242's password:\n",
    "Permission denied, please try again.\n",
    "root@10.10.11.242's password:\n",
    "\n",
    ":~$ ssh admin@10.10.11.242\n",
    "admin@10.10.11.242's password:\n",
    "Permission denied, please try again.\n",
    "admin@10.10.11.242's password:\n",
    "Permission denied, please try again.\n",
    "admin@10.10.11.242's password:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62947ee5-af8e-4735-bbb7-0f1ff2cdc56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e567a5ff-ff6a-4f4e-b9df-20cb1ff75832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =     104.71 ms /   250 runs   (    0.42 ms per token,  2387.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24134.73 ms /   968 tokens (   24.93 ms per token,    40.11 tokens per second)\n",
      "llama_print_timings:        eval time =   88296.46 ms /   249 runs   (  354.60 ms per token,     2.82 tokens per second)\n",
      "llama_print_timings:       total time =  113478.60 ms /  1217 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of the above hydra output is as follows:\n",
      "- Hydra is an open source tool for performing password cracking on remote machines. It is often used to crack into MySQL databases or SSH servers.\n",
      "- Hydra is running with default settings for its verbosity level (-v) and number of concurrent threads (-t). The hydra output indicates that it is trying 14344398 passwords from the file /mnt/d/projects/whiterabbitneo-pentestgpt/rockyou.txt against ssh://10.10.11.242 on port 22 (the default SSH port).\n",
      "- The hydra output shows that it is successfully attempting to authenticate with user 'root' using password '123456' (ATTEMPT 1). It also shows that it is attempting with '12345' (ATTEMPT 2), '123456789' (ATTEMPT 3), etc., up to the total of 14344398 attempts.\n",
      "- The output from hydra also indicates that it is\n"
     ]
    }
   ],
   "source": [
    "summary = input_parser(input_parsing_template, command_output, llm, summary_sampler, max_tokens=250)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1551c005-52e6-4a25-a3cc-976b022e6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries.append(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3716d0ca-8ec3-4063-88b4-f45e82beb285",
   "metadata": {},
   "source": [
    "# Input Parser Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9c5d26be-547c-4d99-8c97-066feed87960",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_parsing_past_summaries_template = \"\"\"SYSTEM:\n",
    "Summarize all the past summaries of terminal output to get the main points as if you are reporting to a senior penetration tester for further guidance. Your output will be provided to another large language model, so the result should be short and precise for token limit reasons.\n",
    "First, comprehensively analyze the output and identify the test results and the vulnerable/non-vulnerable services. This allows for the other model to tackle attacking in a structured way.\n",
    "For each service, given the test result, ensure that all detail that is needed for further testing is kept intact. For instance, you should keep both the port number and the service name/version if a port is open.\n",
    "However, do not hesitate to omit any details that are not important for example, time and basic facts about each program used.\n",
    "Finally, critically evaluate each summary to confirm that only summarization is done and no assumptions or conclusions are made. If reasoning is done omit said reasoning.\n",
    "In conclusion, create a concise summary by evaluating the terminal output to get the key information and vulnerable/non-vulnerable services, ensure all important details remain intact, and critically evaluate that the summary only distills information with no assumptions or conclusions \n",
    "to assist another large language model acting as a senior penetration tester. Ensure that non-necessary details are removed for example, the explanations for how each\n",
    "Always answer without hesitation.\n",
    "SUMMARIES: {prompt}\n",
    "ASSISTANT: The summary of all past terminal outputs is as follows:\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5f07f3c-0c86-49c4-b0cb-d1d2a5b64474",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_combined = \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f6a767a-5593-4b2b-9d5a-dbfceb4df78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nmap scan results is as follows:\n",
      "\n",
      "1. The scan was started at 12:07 EST with Nmap version 7.60.\n",
      "2. The scan was targeting IP 10.10.11.242 on ports 80 and 22 (HTTP and SSH) with a full connect scan.\n",
      "3. The scan discovered an open port 80 (HTTP) running nginx 1.18.0 on port 80 (Ubuntu Linux). It also found an open port 22 (SSH) running OpenSSH 8.2p1 (Ubuntu Linux).\n",
      "4. The scan also performed version detection on ports 80 (HTTP) and 22 (SSH) which identified the server versions.\n",
      "5. The scan did not complete due to timeouts or retransmission caps.\n",
      "6. The scan was conducted over DNS resolution, which takes about 6 seconds.\n",
      "7. The scan was limited to 65535 ports on the target machine due to the full connect scan.\n",
      "8. The scan took approximately 404 seconds to complete.\n",
      "\n",
      " of the above hydra output is as follows:\n",
      "- Hydra is an open source tool for performing password cracking on remote machines. It is often used to crack into MySQL databases or SSH servers.\n",
      "- Hydra is running with default settings for its verbosity level (-v) and number of concurrent threads (-t). The hydra output indicates that it is trying 14344398 passwords from the file /mnt/d/projects/whiterabbitneo-pentestgpt/rockyou.txt against ssh://10.10.11.242 on port 22 (the default SSH port).\n",
      "- The hydra output shows that it is successfully attempting to authenticate with user 'root' using password '123456' (ATTEMPT 1). It also shows that it is attempting with '12345' (ATTEMPT 2), '123456789' (ATTEMPT 3), etc., up to the total of 14344398 attempts.\n",
      "- The output from hydra also indicates that it is\n"
     ]
    }
   ],
   "source": [
    "print(summaries_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c2115de-306a-4a67-9351-78e15344ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_of_summaries_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8dc39b33-d5bc-4286-b4fe-72bb902cc9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  245175.75 ms\n",
      "llama_print_timings:      sample time =     106.66 ms /   250 runs   (    0.43 ms per token,  2343.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18575.57 ms /   824 tokens (   22.54 ms per token,    44.36 tokens per second)\n",
      "llama_print_timings:        eval time =   85921.86 ms /   249 runs   (  345.07 ms per token,     2.90 tokens per second)\n",
      "llama_print_timings:       total time =  105203.38 ms /  1073 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. The Nmap scan on IP 10.10.11.242 revealed two open ports - 80 (HTTP) running nginx 1.18.0 and 22 (SSH) running OpenSSH 8.2p1. Both ports were scanned with version detection enabled. The scan was limited to 65535 ports due to the full connect scan. The scan took about 404 seconds to complete. The scan was conducted over DNS resolution, which takes about 6 seconds per target.\n",
      "2. Hydra is an automated tool for testing SSH services and is attempting to crack passwords against 10.10.11.242 on port 22 using the wordlist /mnt/d/projects/whiterabbitneo-pentestgpt/rockyou.txt. It is performing 14344398 attempts in total. Hydra is attempting common passwords in sequence, from '123456' to '1434569'. If any password is successful, hydra will stop and report back the username and password combination\n"
     ]
    }
   ],
   "source": [
    "past_history = input_parser(input_parsing_past_summaries_template, summaries_combined, llm, summary_of_summaries_sampler, max_tokens=250)\n",
    "print(past_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c438d8-93b1-42bc-8b0d-cef781ee8ac9",
   "metadata": {},
   "source": [
    "issue: As the summary goes on we get wrong conclusions/summary is doing misguided conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd31f88-84cc-4f45-9b2d-19c3d3c931d3",
   "metadata": {},
   "source": [
    "# Reasoning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b15e4aa-65d9-4676-8c1a-26ca8b4f4103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  114165.22 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     2 runs   (    0.23 ms per token,  4385.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7207.07 ms /  1010 tokens (    7.14 ms per token,   140.14 tokens per second)\n",
      "llama_print_timings:        eval time =     257.26 ms /     1 runs   (  257.26 ms per token,     3.89 tokens per second)\n",
      "llama_print_timings:       total time =    7918.31 ms /  1011 tokens\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output_ptt \u001b[38;5;241m=\u001b[39m \u001b[43mreasoning_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreasoning_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_sampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_add_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minitial_access\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecution\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost_exploitation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtodo_task_descriptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mObtain a secret file with a hash in it\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(output_ptt)\n",
      "File \u001b[1;32mD:\\personal_projects\\whiterabbitneo-pentestgpt\\notebooks\\..\\schema.py:116\u001b[0m, in \u001b[0;36mreasoning_module\u001b[1;34m(template, prompt, ptt, llm, sampler, max_spaces, force_add_task, update_status, todo_task_descriptions)\u001b[0m\n\u001b[0;32m    114\u001b[0m     inprogress_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 116\u001b[0m     updated \u001b[38;5;241m=\u001b[39m \u001b[43madd_new_items_outlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minprogress_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_spaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_add_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_add_task\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     num_inprogress \u001b[38;5;241m=\u001b[39m find_inprogress(updated)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\personal_projects\\whiterabbitneo-pentestgpt\\notebooks\\..\\schema.py:256\u001b[0m, in \u001b[0;36madd_new_items_outlines\u001b[1;34m(llm, prompt, ptt, sampler, inprogress_set, max_spaces, force_add_task)\u001b[0m\n\u001b[0;32m    254\u001b[0m continue_choices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m],\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    255\u001b[0m tree_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(ptt)\n\u001b[1;32m--> 256\u001b[0m prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43madd_whitespace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_spaces\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_whitespace(prompt, llm, sampler, max_spaces)\n",
      "File \u001b[1;32mD:\\personal_projects\\whiterabbitneo-pentestgpt\\notebooks\\..\\schema.py:225\u001b[0m, in \u001b[0;36madd_whitespace\u001b[1;34m(prompt, llm, sampler, max_spaces)\u001b[0m\n\u001b[0;32m    219\u001b[0m whitespace_regex \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[ \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn]*\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m generator \u001b[38;5;241m=\u001b[39m outlines\u001b[38;5;241m.\u001b[39mgenerate\u001b[38;5;241m.\u001b[39mregex(\n\u001b[0;32m    221\u001b[0m     llm,\n\u001b[0;32m    222\u001b[0m     whitespace_regex,\n\u001b[0;32m    223\u001b[0m     sampler\u001b[38;5;241m=\u001b[39msampler\n\u001b[0;32m    224\u001b[0m )\n\u001b[1;32m--> 225\u001b[0m whitespace \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_spaces\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m whitespace\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\senior_project\\lib\\site-packages\\outlines\\models\\llamacpp.py:41\u001b[0m, in \u001b[0;36mLlamaSequenceGenerator.__call__\u001b[1;34m(self, prompts, max_tokens, stop_at, rng, **model_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits_processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     processors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits_processor\u001b[38;5;241m.\u001b[39mcopy()]\n\u001b[1;32m---> 41\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcreate_completion(\n\u001b[0;32m     42\u001b[0m     prompt,\n\u001b[0;32m     43\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens,\n\u001b[0;32m     44\u001b[0m     stop\u001b[38;5;241m=\u001b[39mstop_at,\n\u001b[0;32m     45\u001b[0m     seed\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39minitial_seed(),\n\u001b[0;32m     46\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mLogitsProcessorList(processors),\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m     48\u001b[0m )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     49\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\senior_project\\lib\\site-packages\\llama_cpp\\llama.py:1474\u001b[0m, in \u001b[0;36mLlama.create_completion\u001b[1;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[0;32m   1472\u001b[0m     chunks: Iterator[CreateCompletionStreamResponse] \u001b[38;5;241m=\u001b[39m completion_or_chunks\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n\u001b[1;32m-> 1474\u001b[0m completion: Completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompletion_or_chunks\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\senior_project\\lib\\site-packages\\llama_cpp\\llama.py:1000\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[1;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[0;32m    998\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    999\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1000\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m   1001\u001b[0m     prompt_tokens,\n\u001b[0;32m   1002\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[0;32m   1003\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   1004\u001b[0m     min_p\u001b[38;5;241m=\u001b[39mmin_p,\n\u001b[0;32m   1005\u001b[0m     typical_p\u001b[38;5;241m=\u001b[39mtypical_p,\n\u001b[0;32m   1006\u001b[0m     temp\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m   1007\u001b[0m     tfs_z\u001b[38;5;241m=\u001b[39mtfs_z,\n\u001b[0;32m   1008\u001b[0m     mirostat_mode\u001b[38;5;241m=\u001b[39mmirostat_mode,\n\u001b[0;32m   1009\u001b[0m     mirostat_tau\u001b[38;5;241m=\u001b[39mmirostat_tau,\n\u001b[0;32m   1010\u001b[0m     mirostat_eta\u001b[38;5;241m=\u001b[39mmirostat_eta,\n\u001b[0;32m   1011\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39mfrequency_penalty,\n\u001b[0;32m   1012\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39mpresence_penalty,\n\u001b[0;32m   1013\u001b[0m     repeat_penalty\u001b[38;5;241m=\u001b[39mrepeat_penalty,\n\u001b[0;32m   1014\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[0;32m   1015\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m   1016\u001b[0m     grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[0;32m   1017\u001b[0m ):\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_eos:\n\u001b[0;32m   1019\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetokenize(completion_tokens, prev_tokens\u001b[38;5;241m=\u001b[39mprompt_tokens)\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\senior_project\\lib\\site-packages\\llama_cpp\\llama.py:682\u001b[0m, in \u001b[0;36mLlama.generate\u001b[1;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[0;32m    684\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[0;32m    685\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[0;32m    686\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[0;32m    701\u001b[0m         )\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\senior_project\\lib\\site-packages\\llama_cpp\\llama.py:522\u001b[0m, in \u001b[0;36mLlama.eval\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    518\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[0;32m    520\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[0;32m    521\u001b[0m )\n\u001b[1;32m--> 522\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\senior_project\\lib\\site-packages\\llama_cpp\\_internals.py:311\u001b[0m, in \u001b[0;36m_LlamaContext.decode\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 311\u001b[0m return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_ptt = reasoning_module(reasoning_template, summary, ptt, llm, reasoning_sampler, force_add_task={\"recon\": 0, \"initial_access\": 1, \"execution\": 0, \"post_exploitation\": 0}, update_status=True, todo_task_descriptions=[\"Obtain a secret file with a hash in it\"])\n",
    "print(output_ptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc9c45-6a59-4ac0-927b-2f36340dd95f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
